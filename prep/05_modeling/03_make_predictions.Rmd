---
title: "Predict props to cells per flag, year, length"
output: html_document
date: "2025-08-12"
---

# Summary

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(terra)
library(foreach)
library(doParallel)
library(progress)
library(pryr)  # for memory tracking
library(glue)
library(qs)
library(here)
library(janitor)
library(arrow)
library(countrycode)
library(sf)
library(ranger)

source(here("R/dir.R"))
```

## Functions to prepare enviro and effort data  

```{r}
elnino <- read.csv(here("data/model_features/enso_index.csv"))

pdo <- read.csv(here("data/model_features/pdo_index.csv")) 

world_bank <- read.csv(here("data/model_features/world_bank_regions.csv")) 

gfi_df <- read.csv(here("data/model_features/global_fishing_index_governance.csv"))

# Load prepared data
model_data <- readRDS(here("data/model_features/prepared_data_0.5.rds")) %>%
  mutate(year = as.numeric(year)) %>%
  mutate(presence = 1) 

## read in environmental variables

  global_grid <- read.csv(here("data/model_features/global_grid.csv"))
  
  chl_data <- qs::qread(here("data/model_features/chl_data.qs"))
  
  sst_data <- read.csv(here("data/model_features/sst_data.csv"))

  wind_data <- qs::qread(here("data/model_features/wind_data.qs"))

  ocean_data <- sst_data %>%
    left_join(chl_data) %>%
    left_join(wind_data) %>%
    filter(year %in% c(2015:2017))
  
ocean_data_historical <- qs::qread(here("data/int/prediction_historical_data/half_degree/chl_yearly_1950_1980.qs")) %>%
  rbind(qs::qread(here("data/int/prediction_historical_data/half_degree/chl_yearly_1981_2014.qs"))) %>%
  left_join(qs::qread(here("data/int/prediction_historical_data/half_degree/sst_yearly_1950_1980.qs")) %>% 
              rbind(qs::qread(here("data/int/prediction_historical_data/half_degree/sst_yearly_1981_2014.qs"))), by = c("pixel_id", "year")) %>% 
  left_join(qs::qread(here("data/int/prediction_historical_data/half_degree/wind_yearly_1950_2014.qs")) %>% mutate(year = as.numeric(year)), by = c("pixel_id", "year")) %>%
  dplyr::select(-pixel_area_m2.x, -pixel_area_m2.y)

  ocean_data_all <- ocean_data %>%
    rbind(ocean_data_historical) %>%
    dplyr::select(-pixel_area_m2)

  spatial_data <- global_grid %>%
    left_join(read.csv(here("data/model_features/gfw_static_spatial_measures.csv")) %>% dplyr::select(-lat, -lon), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/mesopelagiczones/mesopelagiczones_fixed.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/eez/eez_fix.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/fao/fao_fixed.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/ocean/ocean_fixed.csv")), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/seamounts.csv")), by = "pixel_id") %>% 
   crossing(., year = c(1950:2017))
  
  
 ifa_df <- qs::qread(here("data/model_features/ifa/ifa_fin.qs"))
 
  test_ifa <- ifa_df %>%
   filter(year == 2017) %>%
   dplyr::select(lon, lat, ifa) %>%
   rast(., type = "xyz")
  plot(test_ifa)
 
 sea_ice_df <- qs::qread(here("data/model_features/sea_ice_features_lit.qs"))
 
 test_ice <- sea_ice_df %>%
   filter(year == 2017) %>%
   dplyr::select(lon, lat, sea_ice_present) %>%
   rast(., type = "xyz")
  plot(test_ice)
  
  env_data <- spatial_data %>%
    left_join(ifa_df) %>%
    left_join(sea_ice_df) %>%
    left_join(ocean_data_all) %>% # cool.
    left_join(elnino) %>%
    left_join(pdo) %>%
    left_join(world_bank, by = c("eez_id")) %>%
    mutate(eez_region_world_bank_7 = ifelse(eez_sovereign %in% c("High seas", "Land"), "High seas", eez_region_world_bank_7)) %>% 
    left_join(gfi_df, by = c("eez_sovereign" = "flag_fin")) %>% # add in global fishing index data here
    mutate(gov_score = ifelse(eez_id >= 99999 & is.na(gov_score), "high_seas", gov_score)) %>%
        mutate(gov_score = ifelse(eez_id < 99999 & is.na(gov_score), "no_data", gov_score)) %>%
    dplyr::select(-eez_sovereign, -nearest_seamount_id, -geometry_wkt) %>% 
    distinct()
  
```

```{r}

mollweide_projection <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs"

data_grid_area <- global_grid %>%
    st_as_sf(wkt = "geometry_wkt",
           crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")%>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES", "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  st_transform(mollweide_projection) %>%
  mutate(pixel_area_m2 = st_area(geometry_wkt)%>%
           units::drop_units()) 

hist_fish_data <- qs::qread(here("data/model_features/rousseau_total_art_vessels.qs")) %>%
  mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name")) %>%
  mutate(flag_country_name = 
           case_when(
             flag_fin == "RAA" ~ "Azores", 
             flag_fin == "RAM"  ~ "Madeira",
             TRUE ~ flag_country_name
           ))

  
flags <- unique(hist_fish_data$flag_fin) # get the flags we need to run models for # 151 of them


env_grid <- env_data %>% 
  dplyr::select(lon, lat) %>% distinct()

```


Read in EEZ id and FAO id lookup tables so we can save with the actual iso3c and FAO id numbers

```{r}

eez_lookup <- read.csv(here("data/model_features/eez/eez_lookup_fix.csv")) %>%
  clean_names() %>%
  mutate(eez_country_name = countrycode(eez_sovereign, origin = "iso3c", destination = "country.name")) %>%
    mutate(eez_country_name = 
           case_when(
             eez_sovereign == "RAA" ~ "Azores", 
             eez_sovereign == "RAM"  ~ "Madeira",
             TRUE ~ eez_country_name
           )) %>%
  mutate(eez_country_name = ifelse(is.na(eez_country_name), "High seas", eez_country_name))


fao_lookup <- read.csv(here("data/model_features/fao/fao_major_ids.csv")) %>%
  clean_names() %>%
  dplyr::select(fao_id, "fao_major_fishing_area" = "name_en")

global_grid <- read.csv(here("data/model_features/global_grid.csv")) %>%
  dplyr::select(lon, lat, pixel_id)


access_data <- qs::qread(here("data/int/prediction_historical_data/art_fishing_access.qs")) # probably not necessary for artisanal? 

env_data_fishing_areas <- env_data %>% 
  filter(sea_ice_present == 0,
         ifa == 1) %>%
      left_join(eez_lookup)

test <- env_data %>% 
  left_join(eez_lookup) %>%
  filter(eez_sovereign == "WLF")

# env_grid <- env_data %>% 
#   dplyr::select(lon, lat) %>% distinct()

env_grid_fishing_areas <- env_data_fishing_areas %>% 
  dplyr::select(lon, lat) %>% distinct()

```

After the models are fit, we make predictions on ALL DATA. So stage 1 is in sample predictions (since we fit the stage one model on all data), and stage two will contain out of sample predictions (since we fit the model on only data with fishing effort in it!)

 - Only takes ~7 mins with 40 cores
 
```{r}
stage_1_path <- file.path(rdsi_dir, "prep/random_forest/artisanal_skylight_sentinel/stage_1_models/")
stage_1_files <- list.files(stage_1_path, full.names = TRUE)
stage_1_flags <- unique(sub(".*stage_1_rf_model_full_data_([A-Z]{3})_.*", "\\1", stage_1_files))

stage_2_path <- file.path(rdsi_dir, "prep/random_forest/artisanal_skylight_sentinel/stage_2_models/")
stage_2_files <- list.files(stage_2_path, full.names = TRUE)
stage_2_flags <- unique(sub(".*stage_2_rf_model_full_data_([A-Z]{3})_.*", "\\1", stage_2_files))

diff_flags_1 <- setdiff(stage_1_flags, stage_2_flags)
diff_flags_2 <- setdiff(stage_2_flags, stage_1_flags)

model_flags <- intersect(stage_1_flags, stage_2_flags) # 164

years <- c(1950:2017)

cl <- makeCluster(40) 
registerDoParallel(cl)

 foreach(flag = model_flags, .packages = c("dplyr", "tidyverse", "randomForest", "qs", "glue", "ranger")) %dopar% {

   
 # foreach(yr = years, .packages = c("dplyr", "tidyverse", "randomForest", "qs", "glue", "ranger")) %dopar% {

 for(yr in years) {
   
   ## uncheck this if you arent doing a full rerun 
   # if(file.exists(file.path(rdsi_dir, glue("prep/random_forest/artisanal_skylight_sentinel/predictions/yearly/model_preds_{flag}_{yr}.qs")))){
   #   cat("skipping", "exists")
   #   next()
   # }

# flag = "WLF"
# yr = 2017

# get combination of categories we need to run through our models
model_data_flag <- hist_fish_data %>%
  dplyr::select(flag_fin, length_category, year, nv) %>%
  filter(flag_fin == flag, year == yr)
  
distinct_cats <- model_data_flag %>%
    distinct(flag_fin, length_category) 

full_grid <- tidyr::crossing(env_grid_fishing_areas, distinct_cats) %>%
  crossing(., year = yr)
  
full_data <- full_grid %>%
  left_join(env_data_fishing_areas, by = c("lon", "lat", "year")) %>%
  dplyr::select(-pixel_id) %>%
  filter(eez_sovereign == flag) # we're only gonna make predictions on cells where they can fish - so IFA, no sea ice, and their own EEZ for artisanal

if(nrow(full_data) == 0){
    cat("skipping", flag, yr, "check to make sure this is right")
  next()
}

# read in stage 2 model! 
# Get the list of matching files
matching_files <- list.files(
  path = file.path(rdsi_dir, "prep/random_forest/artisanal_skylight_sentinel/stage_2_models/"), 
  pattern = glue::glue("stage_2_rf_model_full_data_{flag}_.*\\.qs$"),
  full.names = TRUE
)

# Check if a matching file exists
if (length(matching_files) > 0) {
  stage2_model <- qs::qread(matching_files[1])  # Read the first matching file
} else {
  stop("No matching file found for flag: ", flag)
}


set.seed(123)
oos_preds <- full_data %>%
  mutate(pred_prop = predict(stage2_model, data = .)$predictions)

# test <- oos_preds %>%
#   filter(length_category == "Less than 6m") %>%
#   dplyr::select(lon, lat, pred_prop) %>%
#   rast(., type = "xyz") %>%
#   plot()

## read in stage 1 model! 
# Get the list of matching files
matching_files <- list.files(
  path = file.path(rdsi_dir, "prep/random_forest/artisanal_skylight_sentinel/stage_1_models/"), 
  pattern = glue::glue("stage_1_rf_model_full_data_{flag}_.*\\.qs$"),
  full.names = TRUE
)

# Check if a matching file exists
if (length(matching_files) > 0) {
  stage1_model <- qs::qread(matching_files[1])  # Read the first matching file
} else {
  stop("No matching file found for flag: ", flag)
}

set.seed(123)
stage1_preds <- full_data %>%
  mutate(pred_presence = predict(stage1_model, data = .)$predictions[, "1"])

# # for now we will use > 0 in the EEZ to be 1
stage_1_preds_rescale <- stage1_preds %>%
    mutate(pred_presence_rescale = case_when(
        pred_presence > 0 ~ 1, # need to make a decision about the cut off. >=0.5 or >0? If we keep consistent with industrial, then we should do >= 0.5, except when there is no greater than 0.5 for a category, then we use > 0. Then fill the rest with the regional mapping.
        TRUE ~ 0
    )) %>%
  mutate(pred_presence_rescale = ifelse(fao_id %in% c(48, 88, 58), 0, pred_presence_rescale)) # remove any antarctica cells for artisanal just to be safe

# “We prefer to err on the side of inclusion within a flag’s EEZ.”

# stage_1_preds_rescale <- stage1_preds %>%
#   group_by(flag_fin, length_category) %>%
#   mutate(max_pred = max(pred_presence, na.rm = TRUE)) %>%
#   ungroup() %>%
#   left_join(eez_lookup) %>%
#   mutate(pred_presence_rescale = case_when( # adding this so that we will have predictions even if the maximum prob is < 0.5, but only assigning 1 in these cases when the flag country is fishing in their EEZ
#     max_pred < 0.5 & pred_presence > 0 & flag_fin == eez_sovereign ~ 1,
#     max_pred >= 0.5 & pred_presence >= 0.5 ~ 1,
#     TRUE ~ 0
#   )) %>%
#   dplyr::select(-max_pred) %>% # if we run it like this, then Russia for example is really aggregated for 6-12m, but really dispersed for <6m...
#     mutate(pred_presence_rescale =
#            case_when((elevation_m >= -200  & distance_from_shore_m <= 50) & pred_presence_rescale == 1 ~ 1, # limit to 200m depth and 50km offshore. The distance from shore is actually in km not in m
#                      TRUE ~ 0)) %>%
#   mutate(pred_presence_rescale = ifelse(fao_id %in% c(48, 88, 58), 0, pred_presence_rescale)) %>% # remove any antarctica cells for artisanal
#   mutate(pred_presence_rescale = ifelse(sst_c_mean <= 0, 0, pred_presence_rescale))

# test <- stage_1_preds_rescale %>% filter(pred_presence_rescale == 1)

## join stage 1 and 2 preds together and multiply 
all_preds <- oos_preds %>%
  dplyr::select(lat, lon, length_category, year, flag_fin, pred_prop) %>% # probably select lat, lon, gear, length, year, flag here?
  left_join(., stage_1_preds_rescale) %>% 
    dplyr::select(lon, lat, flag_fin, length_category, year, fao_id, eez_id, eez_sovereign, eez_country_name, pred_prop, pred_presence_rescale) %>% 
  left_join(access_data %>% dplyr::select(-eez_sovereign)) %>%
  mutate(access = ifelse(is.na(access), 0, access)) %>% 
  mutate(access = ifelse(eez_sovereign == flag, 1, access)) %>% # don't think we need access for artisanal
  mutate(pred_prop_final = pred_prop*pred_presence_rescale*access) %>%
  filter(pred_prop_final > 0) %>%
  filter(!is.na(pred_prop_final)) %>%
 group_by(year, flag_fin, length_category) %>%
  mutate(prop_vessels_predict_rescale = pred_prop_final / sum(pred_prop_final, na.rm = TRUE)) %>%
 ungroup() %>% # need to rescale the predictions to be between 0 and 1 here so that we can allocate effort
  left_join(hist_fish_data) %>%
  mutate(nv = prop_vessels_predict_rescale*nv) %>%
  left_join(global_grid) %>%
  left_join(fao_lookup) %>%
  left_join(eez_lookup) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, length_category, eez_sovereign, fao_id, fao_major_fishing_area, nv) %>%
  filter(nv > 0) %>%
  mutate(sector = "Artisanal")

if(nrow(all_preds) == 0){
    cat("skipping", flag, yr, "no predictions made...")
  next()
}

# test_preds <- all_preds %>%
#   dplyr::group_by(lon, lat) %>%
#   summarise(nv = sum(nv, na.rm = TRUE)) %>%
#   ungroup() %>%
#   rast(., type = "xyz")
# 
# plot(test_preds)
# plot(log(test_preds+1)) # Cool!

qs::qsave(all_preds, file.path(rdsi_dir, glue("prep/random_forest/artisanal_skylight_sentinel/predictions/yearly/model_preds_{flag}_{yr}.qs"))) # qs is smaller

  }

}

stopCluster(cl)

# test <- model_data %>%
#   filter(flag_fin == "ITA") %>%
#   dplyr::group_by(lon, lat) %>%
#   summarise(nv = sum(nv, na.rm = TRUE)) %>%
#   ungroup() %>%
#   rast(., type = "xyz")
# plot(test)

```

Combine all years for flag and save 

 - only takes a minute
 
```{r}

data_grid_area <- data_grid_area %>%
st_drop_geometry()

days_to_hours_conversion <- qs::qread(here("data/int/hours_to_days_conversion_0.5.qs")) %>%
  rename(lon = x, lat = y) %>%
  left_join(global_grid)

cl <- makeCluster(40)  # could probably increase this? 
registerDoParallel(cl)

foreach(flag = model_flags, .packages = c("qs", "dplyr", "tidyverse", "glue", "countrycode")) %dopar% {
  # flag = "RAM"
  
  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/artisanal_skylight_sentinel/predictions/yearly/"), pattern = flag, full.names = TRUE)
  
    # Skip iteration if no files are found
  if (length(all_files_flag) == 0) next
  
  # hours / hours/day = hours * day/hours = days
  # days*(hours/day) = hours

  all_data_flag <- lapply(all_files_flag, qread) %>%
    bind_rows() %>%
    left_join(eez_lookup) %>%
    mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name")) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, length_category, eez_sovereign, eez_country_name, fao_id, fao_major_fishing_area, nv, sector) %>%
    left_join(hist_fish_data %>%
                dplyr::select(-nv)) %>% 
      mutate(nom_active_fishing_days = nv*days_at_sea*mean_engine_p) %>% # this is days right? yes
  mutate(eff_active_fishing_days = nom_active_fishing_days * (1.0261 ^ (year - 1950))) %>%
        left_join(., days_to_hours_conversion) %>%
    mutate(nom_active_fishing_hours = nom_active_fishing_days*mean,
           eff_active_fishing_hours = eff_active_fishing_days*mean) %>%
        rename(flag_country_iso3c = flag_fin, eez_sovereign_iso3c = eez_sovereign, eez_sovereign_name = eez_country_name, fao_fishing_id = fao_id) %>%
    left_join(data_grid_area) %>%
    mutate(pixel_area_km2 = pixel_area_m2/1000000) %>%
    mutate(nv_km2 = nv/pixel_area_km2,
           eff_days_km2 = eff_active_fishing_days/pixel_area_km2,
           nom_days_km2 = nom_active_fishing_days/pixel_area_km2,
           eff_hours_km2 = eff_active_fishing_hours/pixel_area_km2,
           nom_hours_km2 = nom_active_fishing_hours/pixel_area_km2) %>% # calculate nv per km2 here
    dplyr::select(-days_at_sea, -mean_engine_p, -mean, -nom_active_days, -eff_active_days, -p, -gt)
  
  qs::qsave(all_data_flag, file.path(rdsi_dir, glue("prep/random_forest/artisanal_skylight_sentinel/predictions/model_preds_1950_2017_{flag}.qs")))
}

stopCluster(cl)



test_preds <- qs::qread("/home/ubuntu/data_storage/prep/random_forest/artisanal_skylight_sentinel/predictions/model_preds_1950_2017_IDN.qs") %>%
  filter(year == 2017) %>%
  dplyr::group_by(lon, lat) %>%
  summarise(effort = sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
  ungroup() %>% 
  left_join(data_grid_area) %>%
  mutate(effort_km2 = effort/(pixel_area_m2/1000000)) %>%
  dplyr::select(lon, lat, effort_km2) %>%
  rast(., type = "xyz")

plot(test_preds)

```


Plot NV for 2017

```{r}

test_2017 <- all_data %>%
  filter(year == 2017) %>%
  group_by(lon, lat) %>%
  summarise(nv = sum(nv, na.rm = TRUE)/pixel_area_km2) %>%
  ungroup() %>%
  rast(., type = "xyz")

plot(test_2017)

```

