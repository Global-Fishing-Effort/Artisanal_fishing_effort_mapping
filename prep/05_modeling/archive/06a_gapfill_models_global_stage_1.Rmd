---
title: "Stage 1 Global model for gapfilling"
output: html_document
date: "2024-12-11"
---

# Summary

Here we fit a stage 1 global model which will be used for gapfilling missing flag countries in the Skylight data.

```{r}
knitr::opts_chunk$set(echo = TRUE)

rm(list = ls())

library(tidyverse)
library("qs")
library(foreach)
library(doParallel)
library(here)
library(tictoc)
library(progress)
library(terra)
library(glue)
library(strex)
library(broom)
library(PRROC)
library(janitor)
library(ranger)

source(here("R/dir.R"))

```

## Functions to prepare enviro and effort data  
```{r}
elnino <- read.csv(here("data/model_features/enso_index.csv"))

pdo <- read.csv(here("data/model_features/pdo_index.csv")) 

world_bank <- read.csv(here("data/model_features/world_bank_regions.csv")) 

gfi_df <- read.csv(here("data/model_features/global_fishing_index_governance.csv"))

# Load prepared data
model_data <- readRDS(here("data/model_features/prepared_data_0.5.rds")) %>%
  mutate(year = as.numeric(year)) %>%
  mutate(presence = 1) 

## read in environmental variables

  global_grid <- read.csv(here("data/model_features/global_grid.csv"))
  
  chl_data <- qs::qread(here("data/model_features/chl_data.qs"))
  
  sst_data <- read.csv(here("data/model_features/sst_data.csv"))

  wind_data <- qs::qread(here("data/model_features/wind_data.qs"))

  ocean_data <- sst_data %>%
    left_join(chl_data) %>%
    left_join(wind_data)

  spatial_data <- global_grid %>%
    left_join(read.csv(here("data/model_features/gfw_static_spatial_measures.csv")) %>% dplyr::select(-lat, -lon), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/mesopelagiczones/mesopelagiczones_fixed.csv")), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/eez/eez.csv")), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/fao/fao_fixed.csv")), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/ocean/ocean_fixed.csv")), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/seamounts.csv")), by = "pixel_id") %>% 
    crossing(., year = c(2009:2024)) 
  
  
  env_data <- spatial_data %>%
    left_join(ocean_data) %>% # cool.
    dplyr::select(-geometry_wkt) %>%
    left_join(elnino) %>%
    left_join(pdo) %>%
    left_join(world_bank, by = c("eez_id")) %>%
    mutate(eez_region_world_bank_7 = ifelse(eez_sovereign %in% c("High seas", "Land"), "High seas", eez_region_world_bank_7)) %>% 
    left_join(gfi_df, by = c("eez_sovereign" = "flag_fin")) %>% # add in global fishing index data here
    mutate(gov_score = ifelse(eez_id >= 99999 & is.na(gov_score), "high_seas", gov_score)) %>%
        mutate(gov_score = ifelse(eez_id < 99999 & is.na(gov_score), "no_data", gov_score)) %>%
    dplyr::select(-eez_sovereign, -nearest_seamount_id) %>% 
    distinct() 
  
  

```

## Specify model formula and regions to run 

```{r}

# Prepare model formula
# apply model on train 
model_formula_rf <- formula(
  presence ~ 
    # Categorical/factor predictors
    length_category +
    meso_id +
    eez_id +
    fao_id +
    eez_region_world_bank_7 + # world bank regions
    ocean +  # Spatial categorical variables
    gov_score + # global fishing index; make sure this is categorical and not a numeric variable
    # Continuous predictors
    lon + lat + 
    elevation_m + # depth
    distance_from_port_m + 
    distance_from_shore_m +
    chl_mg_per_m3_mean + 
    chl_mg_per_m3_sd +
    sst_c_mean + 
    sst_c_sd +
    wind_speed_ms_mean + 
    wind_speed_ms_sd +
    enso_index_mean + # el nino data 
    enso_index_sd + # pacific decadal oscillation
    pdo_index_mean +  
    pdo_index_sd + 
    nearest_seamount_distance_m + 
    year 
)
  
env_grid <- env_data %>% 
  dplyr::select(lon, lat) %>% distinct()

## ok we could use the world bank regions

hist_fish_data <- qs::qread(here("data/model_features/rousseau_total_art_vessels.qs")) %>%
    filter(nv > 0) 

```

## Run models and variable selection

 - calculate the full model using all variables available
 - calculate variable importance metrics and RMSE or AUC
 - Set a threshold of the 10th quantile of the variable importance (GINI index for classification) and remove any variables with variable importance less than that
 - Rerun model with new variables and calculate model importance metrics and AUC-PR again
 - If the AUC doesn't increase at all, we stop the model pruning, if it does, we continue, hoping that the AUC will improve even more in the next iteration. 
 - If the threshold doesn't remove any variables, we increase the threshold by 1% until a variable is removed, and rerun the process
 - We loop through this until the AUC does not improve at all. 
 
 NOTE: lets use Area Under the Precision-Recall Curve (AUC-PR) instead of RMSE because RMSE isn't really relevant to classification regression; Higher AUC-PR value is better. 
 
  - 109 mins with 500 trees

```{r}

model_data_loop <- model_data %>% 
  distinct(lon, lat, year, length_category, presence)

  
  distinct_cats <- model_data_loop %>%
    distinct(year, length_category)
  
  full_grid <- tidyr::crossing(env_grid, distinct_cats)
  
  full_data <- full_grid %>%
    left_join(env_data, by = c("lon", "lat", "year")) %>%
    left_join(model_data_loop, by = c("lon", "lat", "year", "length_category")) %>%
    mutate(presence = ifelse(is.na(presence), 0, presence)) %>%
    dplyr::select(-pixel_id)
  
  data_random_forest <- full_data %>% 
    na.omit() %>%
    mutate(presence = as.factor(presence)) %>%
    distinct()

  # Split data into training and testing sets
  set.seed(123)
  samp <- sample(nrow(data_random_forest), 0.6 * nrow(data_random_forest)) 
  train <- data_random_forest[samp, ]
  test <- data_random_forest[-samp, ]
  
  tic()
model <- ranger(
  formula = model_formula_rf,
  data = train,
  num.trees = 500,
  importance = "impurity",
  classification = TRUE,
  probability = TRUE,
  write.forest = TRUE
  )
  toc()
  
  var_imp_i <- data.frame(importance(model))
  
  n_vars <- nrow(var_imp_i)
  qs::qsave(model, glue(file.path(rdsi_dir, "prep/random_forest/artisanal_minderoo/stage_1_models_global/pruning/stage_1_rf_train_global_{n_vars}.qs")))


```
 
Now apply variable selection methods 
 - ~3 hours 500 trees

```{r}
# Threshold-Based Selection: Remove variables with importance scores below a certain threshold (e.g., the median or a predefined percentage of the highest importance value).
# Recursive Feature Elimination (RFE): Iteratively remove the least important variable and re-run the model until performance stabilizes. - NOTE: this would probably be the best option, but would take the longest 
#### How to check when model performance stabilizes?? Look at AUC-PR vs number of variables in each model. When the AUC-PR stops getting better is where you make the variable delineation.  


## lets try the threshold based selection, where the threshold is 10% of max importance score (i.e. we keep any variable that is above that 10% of max importance score) and rerun the model and test to see if RMSE improves or not 

  auc_values <- c()
  num_vars <- c()
  model_data_region <- model_data_loop %>%
    dplyr::distinct(lon, lat, length_category, year, presence) 
  
  distinct_cats <- model_data_region %>%
    distinct(year, length_category)
  
  full_grid <- tidyr::crossing(env_grid, distinct_cats)
  
  full_data <- full_grid %>%
    left_join(env_data, by = c("lon", "lat", "year")) %>%
    left_join(model_data_region, by = c("lon", "lat", "year", "length_category")) %>%
    mutate(presence = ifelse(is.na(presence), 0, presence)) %>%
    dplyr::select(-pixel_id)
  
  data_random_forest <- full_data %>% 
    na.omit() %>%
    mutate(presence = as.factor(presence)) %>%
    distinct()
  
  # Split data into training and testing sets
  set.seed(123)
  samp <- sample(nrow(data_random_forest), 0.6 * nrow(data_random_forest)) 
  train <- data_random_forest[samp, ]
  test <- data_random_forest[-samp, ]
  
  base_model_path <- glue(file.path(rdsi_dir, "prep/random_forest/artisanal_minderoo/stage_1_models_global/pruning/stage_1_rf_train_global_24.qs"))
  
  # Train or load initial model
  if (!file.exists(base_model_path)) {
    tic()
      model <- ranger(
        formula = model_formula_rf,
        data = train,
        num.trees = 500,
        importance = "impurity",
        classification = TRUE,
        probability = TRUE,
        write.forest = TRUE
      )
    toc()
    qs::qsave(model, base_model_path)
  } else {
    model <- qs::qread(base_model_path)
  }
  
  var_imp <- data.frame(importance(model)) %>%
    rename("importance" = 1)
  initial_num_vars <- nrow(var_imp)
  num_vars <- c(initial_num_vars)
  
  threshold <- quantile(var_imp[, "importance"], 0.10)
  
  if (threshold == 0) threshold <- 1e-7
  
    prob <- as.data.frame(predict(model, data = test)$predictions) %>%
        mutate(presence = ifelse(`1` >= 0.5, 1, 0))
  pred_probs <- prob[, "presence"]
  
  true_labels <- as.numeric(as.character(test$presence))
  
  pr_curve <- pr.curve(scores.class0 = pred_probs, weights.class0 = true_labels, curve = TRUE)
  auc_pr <- pr_curve$auc.integral
  auc_values <- c(auc_values, auc_pr)
  
  iteration <- 1
  max_iterations <- 50  # Safety cap to prevent infinite loops
  
repeat {
    
     selected_vars <- var_imp %>% 
     filter(importance > threshold) %>%
      row.names()
   
    selected_vars <- unique(c("year", selected_vars)) # always retain year
    
    if (length(selected_vars) < 6) {
      cat(region_loop, " - Fewer than 6 variables remaining. Stopping.\n")
      break
    }
    
    # Gradually increase threshold until variables are removed
    while (length(selected_vars) == num_vars[length(num_vars)]) {
      threshold <- threshold * 1.01

          selected_vars <- var_imp %>% 
     filter(importance > threshold) %>%
      row.names()
   
    selected_vars <- unique(c("year", selected_vars)) # always retain year 
    }
    
    if (length(selected_vars) < 6) break
    
        file_path <- glue(file.path(rdsi_dir, "prep/random_forest/artisanal_minderoo/stage_1_models_global/pruning/stage_1_rf_train_global_{length(selected_vars)}.qs"))
   
   if(!file.exists(file_path)){
   
     model_i <- ranger(
        formula = presence ~ .,
        data = train[, c("presence", selected_vars)],
        num.trees = 500,
        importance = "impurity",
        classification = TRUE,
        probability = TRUE,
        write.forest = TRUE
      )
     
   }else{
     
     model_i <- qs::qread(file_path)
   }
     
    var_imp <- data.frame(importance(model_i)) %>%
      rename("importance" = 1)
    
    threshold <- quantile(var_imp[, 1], 0.10)

    if (threshold == 0) threshold <- 1e-7
    
      prob_i <- as.data.frame(predict(model_i, data = test)$predictions) %>%
          mutate(presence = ifelse(`1` >= 0.5, 1, 0))
    pred_probs_i <- prob_i[, "presence"]
    pr_curve_i <- pr.curve(scores.class0 = pred_probs_i, weights.class0 = true_labels, curve = TRUE)
    auc_pr_i <- pr_curve_i$auc.integral
    
    auc_values <- c(auc_values, auc_pr_i)
    num_vars <- c(num_vars, length(selected_vars))
    

    if (!file.exists(file_path)) {
      qs::qsave(model_i, file_path)
    }
    
    if (length(auc_values) > 1) {
      improvement <- auc_values[length(auc_values)] - auc_values[length(auc_values) - 1]
      if (improvement <= 0) {
        cat(region_loop, " - AUC did not improve. Stopping.\n")
        break
      }
    }
    
    iteration <- iteration + 1
    if (iteration > max_iterations) {
      cat(region_loop, " - Reached max iterations. Stopping.\n")
      break
      }
    }
  

```

Now write code to select the "best" model per the variable selection from above. We will rerun the model with just those variables on the FULL dataset to leverage all of the data from skylight and save

 - Takes ~2.5 hours with 500 trees
 
```{r}

# Grab the flags that were run in the folder
stage_1_path <- file.path(rdsi_dir, "prep/random_forest/artisanal_minderoo/stage_1_models_global/pruning")

# ----------------------------------------------------
# PREP: Grab "best" model and formula for each region
# ----------------------------------------------------

  region_files <- list.files(stage_1_path)
  
  # Extract number of variables from filenames
  n_variables <- as.numeric(str_before_first(str_after_last(region_files, "_"), "\\."))
  
  if (length(n_variables) > 1) {
    best_model_n <- as.character(sort(n_variables)[2])  # Next to lowest
  } else {
    best_model_n <- as.character(n_variables[1])
  }
  
  # Load model and extract formula
  best_train_model <- qs::qread(file.path(stage_1_path, glue("stage_1_rf_train_global_{best_model_n}.qs")))
  
  expanded_formula <- as.formula(
  paste("presence ~", paste(best_train_model$forest$independent.variable.names, collapse = " + "))
)

  rf_formula <- as.formula(deparse(formula(expanded_formula)) |> paste(collapse = " "))
  
  formula_text <- deparse(rf_formula)
  formula_text <- paste(formula_text, collapse = " ")
  rf_formula_fin <- formula(formula_text)
  
  # Get pre-built formula and best model n for this region
  rf_formula <- rf_formula_fin

  # Filter model data for this region
  model_data_region <- model_data_loop %>%
    dplyr::distinct(lon, lat, length_category, year, presence)
  
  # Generate full prediction grid
  distinct_cats <- model_data_region %>%
    distinct(year, length_category)
  
  full_grid <- tidyr::crossing(env_grid, distinct_cats)
  
  full_data <- full_grid %>%
    left_join(env_data, by = c("lon", "lat", "year")) %>%
    left_join(model_data_region, by = c("lon", "lat", "year", "length_category")) %>%
    mutate(presence = ifelse(is.na(presence), 0, presence)) %>%
    dplyr::select(-pixel_id)
  
  # Prepare data for random forest
  data_random_forest <- full_data %>% 
    na.omit() %>%
    mutate(presence = as.factor(presence)) %>%
    distinct()
  
  # Fit final model
  set.seed(123)
  tic()
  
  model <- ranger(
  formula = rf_formula,
  data = data_random_forest,
  num.trees = 500,
  importance = "impurity",
  classification = TRUE,
  probability = TRUE,
  write.forest = TRUE
  )
  toc()

  # Save model
  qs::qsave(model, glue(file.path(rdsi_dir, "prep/random_forest/artisanal_minderoo/stage_1_models_global/stage_1_rf_model_full_data_global_{best_model_n}.qs")))


```

