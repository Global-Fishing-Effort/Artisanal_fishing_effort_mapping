---
title: "Save data for Zenodo publishing"
output: html_document
date: "2024-12-11"
---

# Summary

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(terra)
library(foreach)
library(doParallel)
library(glue)
library(qs)
library(here)
library(countrycode)
library(strex)

source(here("R/dir.R"))
```


Save csv files to upload to Zenodo and the app 

 - We need to grab any gapfilled flags that are not in the flag level modelling from the regional level modelling 

```{r}

  modelled_flags_original <- str_before_first(str_after_last(list.files(file.path(rdsi_dir, "prep/random_forest/artisanal_skylight_sentinel/predictions/"), pattern = ".qs", full.names = TRUE), "_"), "\\.qs")

#   modelled_flags_regional <- str_before_first(str_after_last(list.files(file.path(rdsi_dir, "prep/random_forest/artisanal_skylight_sentinel/predictions_regional/"), pattern = ".qs", full.names = TRUE), "_"), "\\.qs")
#   
# flags_to_gapfill <- setdiff(modelled_flags_regional, modelled_flags_original)


# all_flags <- c(modelled_flags_original, flags_to_gapfill)

all_flags <- unique(modelled_flags_original)


cl <- makeCluster(24)  # could probably increase this? 
registerDoParallel(cl)


foreach(flag = all_flags, .packages = c("qs", "dplyr", "tidyverse", "glue", "countrycode")) %dopar% {
  # flag = "RAA"
  
  
  all_files_flag_original <- list.files(file.path(rdsi_dir, "prep/random_forest/artisanal_skylight_sentinel/predictions/"), pattern = flag, full.names = TRUE)
  # all_files_flag_regional_gf <- list.files(file.path(rdsi_dir, "prep/random_forest/predictions_regional/"), pattern = flag, full.names = TRUE)

  
  #   # Skip iteration if no files are found
  # if (length(all_files_flag) == 0) next
  

  all_data_flag_original <- lapply(all_files_flag_original, qread) %>%
    bind_rows() %>%
    mutate(data_type = "flag model")

  
  # all_data_flag_regional_gf <- lapply(all_files_flag_regional_gf, qread) %>%
  #   bind_rows()  %>%
  #   mutate(data_type = "regional model")
  
    if(nrow(all_data_flag_original) == 0){
    
    all_data_flag_original <- all_data_flag_regional_gf %>%
      mutate(nom_active_fishing_hours = 0, eff_active_fishing_hours = 0, nom_active_fishing_days = 0, eff_active_fishing_days = 0, eff_days_km2 = 0, nom_days_km2 = 0, eff_hours_km2 = 0, nom_hours_km2 = 0, data_type = NA)
    
  }
  
  # original_cats <- all_data_flag_original %>%
  #   filter(nom_active_fishing_hours > 0) %>%
  #   distinct(year, flag_country_iso3c, gear, length_category) 
  # 
  # regional_cats <- all_data_flag_regional_gf %>%
  #   filter(nom_active_fishing_hours > 0) %>%
  #   distinct(year, flag_country_iso3c, gear, length_category) 
  # 
  # missing_cats <- regional_cats %>%
  #  anti_join(original_cats, by = c("year", "flag_country_iso3c", "gear", "length_category"))
# 
#   
#   data_to_add <- all_data_flag_regional_gf %>%
#     semi_join(missing_cats, by = c("flag_country_iso3c", "year", "gear", "length_category"))
  
  # test <- data_to_add %>%
  #   filter(nom_active_fishing_hours > 0) %>%
  #   distinct(year, flag_country_iso3c, gear, length_category)
  
  all_data_fin <- all_data_flag_original %>%
    filter(nom_active_fishing_hours > 0) %>%
   # rbind(data_to_add) %>%
    mutate(flag_country_name = case_when(
      flag_country_iso3c == "RAA" ~ "Azores", 
      flag_country_iso3c == "RAM" ~ "Madeira", 
      TRUE ~ flag_country_name
    )) %>%
    mutate(flag_country_iso3c = flag)
    # mutate(flag_country_iso3c = as.character(flag_country_iso3c))
  
  # test <- all_data_fin %>%
  #   # filter(year >= 1988) %>%
  #   group_by(flag_country_iso3c, gear, length_category) %>%
  #   summarise(total_effort = sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
  #   ungroup()
  # 
  # test2 <- hist_fish_data %>%
  #       #filter(year >= 1988) %>%
  #   filter(flag_country_iso3c == "IDN")  %>%
  #       group_by(flag_country_iso3c, gear, length_category) %>%
  #   summarise(total_effort = sum(total_nominal_fishing_hours, na.rm = TRUE)) %>%
  #   ungroup()
  # 
  
  write.csv(all_data_fin, file.path(rdsi_dir, glue("prep/random_forest/zenodo_data/artisanal_skylight_sentinel/mapped_by_flag_country/model_preds_1950_2017_{flag}.csv")), row.names = FALSE)
}

stopCluster(cl)


## save as one large csv

  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/zenodo_data/artisanal_skylight_sentinel/mapped_by_flag_country/"), full.names = TRUE)
  
#   bad <- keep(all_files_flag, function(f) {
#   cls <- sapply(read.csv(f, stringsAsFactors = FALSE, nrows = 100), class)
#   "flag_country_iso3c" %in% names(cls) && cls[["flag_country_iso3c"]] != "character"
# })
# bad

    all_data <- lapply(all_files_flag, read.csv) %>%
      bind_rows()
    
    test <- all_data %>%
      filter(year == 2017) %>%
      group_by(lon, lat) %>% 
      summarise(effort = sum(nom_active_fishing_hours, na.rm = TRUE)) %>% 
      ungroup() %>%
      rast(., type = "xyz")
    
    plot(log(test+1))
    plot(test)
    
write.csv(all_data, file.path(rdsi_dir, "prep/random_forest/zenodo_data/artisanal_skylight_sentinel/mapped_artisanal_effort_predictions_1950_2017.csv"), row.names = FALSE)

all_data_grouped <- all_data %>% 
  group_by(year, flag_country_iso3c, flag_country_name, length_category, eez_sovereign_iso3c, eez_sovereign_name, fao_fishing_id, fao_major_fishing_area, sector) %>%
  summarise(eff_active_fishing_hours = sum(eff_active_fishing_hours, na.rm = TRUE), 
            eff_active_fishing_days = sum(eff_active_fishing_days, na.rm = TRUE), 
            nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE), 
            nom_active_fishing_days = sum(nom_active_fishing_days, na.rm = TRUE),
            nv = sum(nv, na.rm = TRUE)) %>%
  ungroup()


write.csv(all_data_grouped, file.path(rdsi_dir, "prep/random_forest/zenodo_data/artisanal_skylight_sentinel/artisanal_effort_predictions_by_flag_eez_fao_gear_length_1950_2017.csv"), row.names = FALSE)



  all_data_grouped <- read.csv(file.path(rdsi_dir, "prep/random_forest/zenodo_data/artisanal_skylight_sentinel/artisanal_effort_predictions_by_flag_eez_fao_gear_length_1950_2017.csv"))
  
all_data_grouped_2 <- all_data_grouped %>% 
  group_by(year, flag_country_iso3c, flag_country_name, length_category) %>%
    summarise(modeled_eff_active_fishing_hours = sum(eff_active_fishing_hours, na.rm = TRUE), 
            modeled_eff_active_fishing_days = sum(eff_active_fishing_days, na.rm = TRUE), 
            modeled_nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE), 
            modeled_nom_active_fishing_days = sum(nom_active_fishing_days, na.rm = TRUE),
            modeled_nv = sum(nv, na.rm = TRUE)) %>%
  ungroup() %>%
    mutate(flag_country_name = case_when(
          flag_country_iso3c == "RAM" ~ "Madeira",
          flag_country_iso3c == "RAA" ~ "Azores", 
          TRUE ~ flag_country_name
  ))

hist_fish_data <- qs::qread(here("data/model_features/rousseau_total_art_vessels.qs")) %>%
    dplyr::select(flag_country_iso3c = flag_fin, year, length_category, total_nv = nv, total_eff_days = eff_active_days, total_nom_days = nom_active_days) %>%
        filter(total_nv > 0) %>%
  mutate(flag_country_name = countrycode(flag_country_iso3c, origin = "iso3c", destination = "country.name")) %>%
  mutate(flag_country_name = case_when(
          flag_country_iso3c == "RAM" ~ "Madeira",
          flag_country_iso3c == "RAA" ~ "Azores", 
          TRUE ~ flag_country_name
  )) %>% 
  left_join(all_data_grouped_2) %>%
  mutate(proportion_nv_modeled = modeled_nv/total_nv,
         prop_nom_days_modeled = modeled_nom_active_fishing_days/total_nom_days)

missing_data <- hist_fish_data %>%
  filter(proportion_nv_modeled != 1) %>%
  filter(proportion_nv_modeled < 0.9999) # 0 awesome! 

write.csv(hist_fish_data, file.path(rdsi_dir, "prep/random_forest/zenodo_data/artisanal_skylight_sentinel/known_artisanal_effort_rousseau.csv"), row.names = FALSE)




test <- hist_fish_data %>% filter(flag_country_iso3c == "UKR", year == 1950)

sum(test$modeled_nom_active_fishing_hours) # 


```


```{r}
test <- hist_fish_data %>%
  filter(flag_country_iso3c %in% c("NOR", "NAM", "AUS", "NZL"))
```

Why does Norway stop in 1983? 
Australia stops in 2016? 
There is no New Zealand or Namibia at all? 

According to supplementary info from Rousseau et al. 2019 PNAS (https://www.pnas.org/doi/10.1073/pnas.1820344116#supplementary-materials):
 - Namibia has no artisanal fishing
 - Norway only has artisanal <12m until 2015? Feels like this is a mistake that wasn't corrected? 
 - New Zealand artisanal stopped in 2010? Also feels like a mistake. Seems like they should've carried over the definiton of artisanal to the latest year.. 
 - Australia artisanal is <10m and stopped in 2014? Definitely is not true. 

```{r}
library(janitor)
# read in published data
rousseau_eff <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/TotalEffortby_FishingCountry_LengthBoat_Gear_Sector.csv") %>% 
  clean_names() %>%
  filter(country %in% c("NOR", "NAM", "AUS", "NZL"),
         sector %in% c("UP", "APW"))

unique(rousseau_eff$sector) # UP only - weird
unique(rousseau_eff$country) # [1] "AUS" "NOR" - no NZL or NAM? 

test_years <- rousseau_eff %>%
  group_by(country, year) %>% 
  summarise(nv = sum(nv, na.rm = TRUE)) %>%
  ungroup()

# AUS to 2016, NOR to 1983 

## lets look at other published data from Rousseau and see if it is the same.. maybe it is a problem with the dataset we're using? 
options(timeout = 600)   # default is 60s; make it longer
mapped_2017_apw <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/effort_mapped/mapped_2017_APW.csv")

mapped_2017_up <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/effort_mapped/mapped_2017_UP.csv")
saup_codes <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/SAUPtoCountry.csv") %>%
  dplyr::select(-X)

mapped_2017_apw_up <- rbind(mapped_2017_apw, mapped_2017_up) %>%
  left_join(saup_codes)


# AUS = 36, 
# NZL = 554, 
# NOR = 578, 
# NAM = 516

test_missing <- mapped_2017_apw_up %>%
 # filter(SAUP %in% c(36, 554, 578, 516))
  filter(Country %in% c("NOR", "AUS", "NAM", "NZL")) # ok so these are all missing from 2017... just like the other dataset. I wonder if it just an artifact of what they are considering as artisanal? 

test_nam <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/effort_mapped_country/mapped_516.csv") # only industrial? Weird. According to google fisheries in Namibia are mostly industrial. 

test <- test_nam %>%
  group_by(Lon, Lat) %>%
  summarise(nom_eff = sum(NomActive, na.rm = TRUE)) %>%
  ungroup() %>%
  na.omit() %>%
 # filter(nom_eff > 1) %>%
  rast(., type = "xyz")

plot(test) # weird how spread out it is.. SAUP is much more concentrated in NAM EEZ, which makes sense. That is also how our industrial is. 

```

